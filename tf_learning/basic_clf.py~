#!/usr/bin/python 
# -*- coding: UTF-8 -*-

import tensorflow as tf
from tensorflow import keras
from tensorflow.examples.tutorials.mnist import input_data
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

data = input_data.read_data_sets('data/fashion')

train_images = data.train.images/255.0
train_labels = data.train.labels
test_images = data.test.images/255.0
test_labels = data.test.labels
print 'train images:', len(train_images), 'train labels:', len(train_labels)
print 'test images:', len(test_images), 'test labels', len(test_labels)

class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']

def log_reg():
    # 训练LR模型，并进行预测
    model = LogisticRegression(penalty='l2')
    model.fit(train_images, train_labels)
    test_pred = model.predict(test_images)
    print classification_report(test_labels, test_pred), '(logistic regression)'

def gbdt():
    # n_estimators = 90 , min_samples_split=800, max_depth=17, min_samples_leaf=60, subsample=0.9
    # model = GradientBoostingClassifier(random_state=10, n_estimators=90,
    #                                    min_samples_split=800, max_depth=17,
    #                                    min_samples_leaf=60, subsample=0.9)
    model = GradientBoostingClassifier()
    model.fit(train_images, train_labels)
    test_pred = model.predict(test_images)
    print classification_report(test_label, test_pred), '(gdbt)'

def preprocessing():
    plt.figure(figsize=(10,10))
    for i in range(25):
        plt.subplot(5,5,i+1)
        plt.xticks([])
        plt.yticks([])
        plt.grid(False)
        plt.imshow(train_images[i], cmap=plt.cm.binary)
        plt.xlabel(class_names[train_labels[i]])

# 构建模型
model = keras.Sequential([
    keras.layers.Flatten(input_shap=(784,)),
    keras.layers.Dense(128, activation=tf.nn.relu),
    keras.layers.Dense(10, activation=tf.nn.softmax)
])

# 编译模型
model.compile(optimizer=tf.train.AdamOptimizer(),
        loss = 'sparse_categorical_crossentropy',
        metrics = ['accuracy'])

# 训练模型
model.fit(train_images, train_labels, epochs = 5)

# 模型评估
test_loss, test_acc = model.evaluate(test_images, test_labels)
print 'test accuracy:', test_acc
